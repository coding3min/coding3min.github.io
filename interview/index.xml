<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Interviews on 程序员的魔法书</title><link>https://leetcode.coding3min.com/interview/</link><description>Recent content in Interviews on 程序员的魔法书</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://leetcode.coding3min.com/interview/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://leetcode.coding3min.com/interview/cao-zuo-xi-tong/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/cao-zuo-xi-tong/</guid><description>操作系统 # 并发和并行的理解？ # 并发：在一个时间段中多个程序都启动运行在同一个处理机中，比如线程 并行：假设目前A，B两个进程，两个进程分别由不同的 CPU 管理执行，两个进程不抢占 CPU 资源且可以同时运行，这叫做并行。单核CPU是伪并行 线程与进程的优缺点 # 多线程的优点：
更加高效的内存共享。多进程下内存共享不便； 较轻的上下文切换。因为不用切换地址空间，CR3寄存器和清空TLB。 多进程的优点：
各个进程有自己内存空间，所以具有更强的容错性，不至于一个集成crash导致系统崩溃 具有更好的伸缩性，因为进程将地址空间，页表等进行了隔离，可以在不同的服务器上进行水平伸缩 如何提升多线程的效率？ # 答者：彬
使用线程池，减少线程的创建销毁带来的开销 根据不同的线程类型确定线程数量，例如cpu繁琐的，核线比1:2，I/O繁琐的1:1 压测，看具体项目能吃多少线程 在线程数无法减少的情况下，根据物理内存调整jvm堆大小，为线程提供足够内存空间 升级物理机的cpu和内存 单台机极限的情况下，使用集群 最基本的，优化代码，减低复杂度 小熊补充
尽量使用线程池，从而不用频繁的创建，销毁线程； 减少线程之间的同步和通信； 通过Huge Page的方式避免产生大量的缺页异常； 避免需要频繁共享写的数据。 进程的三个状态 # 就绪 —&amp;gt; 执行：准备就绪，调度器满足了的需求 执行 —&amp;gt; 阻塞：正在执行的进程由于发生某事件（例如请求I/O而等待I/O完成等）而暂时无法继续执行时，便放弃处理机而处于暂停状态，这时即使把处理机分配给进程也无法运行，故称该进程处于阻塞状态。 阻塞 —&amp;gt; 就绪：处于阻塞状态的进程，在其等待的事件已经发生，如输入/输出完成，资源得到满足或错误处理完毕时，处于等待状态的进程并不马上转入执行状态，而是先转入就绪状态，然后再由系统进程调度程序在适当的时候将该进程转为执行状态； 执行 —&amp;gt; 就绪：正在执行的进程，因时间片用完而被暂停执行，或在采用抢先式优先级调度算法的系统中, 当有更高优先级的进程要运行而被迫让出处理机时，该进程便由执行状态转变为就绪状态。 进程与线程有什么区别？ # 进程是资源分配的最小单位，线程是进程的一个实体，也是 CPU 调度和分派的基本单位，它是比进程更小的能独立运行的基本单位，有时又被称为轻量级进程。 创建进程或撤销进程，系统都要为之分配或回收资源，操作系统开销远大于创建或撤销线程时的开销； 不同进程地址空间相互独立，同一进程内的线程共享同一地址空间。一个进程的线程在另一个进程内是不可见的； 进程间不会相互影响，而一个线程挂掉将可能导致整个进程挂掉； 所以</description></item><item><title/><link>https://leetcode.coding3min.com/interview/docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/docker/</guid><description>Docker # 介绍docker # docker是go开发的，基于Apache2.0协议开源，可以把应用和他的依赖打包到一个轻量级、方便移植的系统中，主要解决的问题是快速发布、自动化构建、统一测试成功的环境和线上环境
docker分为镜像、容器、仓库，打包好的叫镜像，存储镜像的地方叫仓库，镜像运行起来叫容器
容器也可以理解成进程，只不过做了隔离和资源限制，方便管理，对于容器内部的进程来说就好像是一个独立的操作系统
因为镜像小，方便创建和效果所以伸缩、管理、部署起来更为容易
隔离是怎么做的? # 用namespace做的
资源限制是怎么做的？ # 用cgroup做的，对cpu和内存做了限制
听过镜像分层吗？ # 按层构建，基于一个基础层添加新层，前一层是后一层的基础，构建完就变成只读的了，每一层都意味着不同的操作指令，比如初始化环境、程序入口等
docker网络模式 # Docker使用Linux的Namespaces技术来进行资源隔离
container模式：和一个已经存在的容器共享Network namespace，不创建自己的网卡，也不配置自己的ip，共享同一个ip和共享的端口范围，但文件系统和进程列表还是隔离的，同样是用到veth设置拉到docker0上，docker0是默认网关，转发到宿主机上 host模式：和主机共享网络，但文件系统和进程列表还是隔离的，容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口 none模式：Docker容器拥有自己的Network Namespace，但不为Docker容器进行任何网络配置，没有网卡、IP、路由等信息 bridge模式：默认模式，在主机上创建一个名为 docker0 的虚拟网桥，此主机上启动的 Docker 容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。 从 docker0 子网中分配一个 IP 给容器使用，并设置 docker0 的 IP 地址为容器的默认网关。在主机上创建一对虚拟网卡 veth pair 设备，Docker 将 veth pair 设备的一端放在新创建的容器中，并命名为 eth0 （容器的网卡），另一端放在主机中，以 vethxxx 这样类似的名字命名，并将这个网络设备加入到 docker0 网桥中。可以通过 brctl show 命令查看。 选择一个和宿主机不同的IP地址和子网分配给docker0，连接到docker0的容器就从这个子网中选择一个未占用的IP使用</description></item><item><title/><link>https://leetcode.coding3min.com/interview/go/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/go/</guid><description>Go # 基本数据类型 # goroutine # 框架 # gin # 线程和协程，有什么区别，为什么协程可以创建很多 # 答者：记事本
线程由系统调度，协程由运行时调度
而为什么协程可以做到同时创建上万个，是因为go的协程初始化资源是4KB空间，比线程轻量级
网上：
区别在于
一个线程可以多个协程，一个进程也可以单独拥有多个协程。 线程进程都是同步机制，而协程则是异步。 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态。 线程是抢占式，而协程是非抢占式的，所以需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。 协程并不是取代线程, 而且抽象于线程之上, 线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行, 线程是协程的资源, 但协程不会直接使用线程, 协程直接利用的是执行器(Interceptor), 执行器可以关联任意线程或线程池, 可以使当前线程, UI线程, 或新建新程.。 线程是协程的资源。协程通过Interceptor来间接使用线程这个资源。 协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此：
协程的好处：
无需线程上下文切换的开销 无需原子操作锁定及同步的开销 方便切换控制流，简化编程模型 缺点：
无法利用多核资源：协程的本质是个单线程,它不能同时将 单个CPU 的多个核用上,协程需要和进程配合才能运行在多CPU上.当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。 进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序 最佳实践
线程和协程推荐在IO密集型的任务(比如网络调用)中使用，而在CPU密集型的任务中，表现较差。 对于CPU密集型的任务，则需要多个进程，绕开GIL的限制，利用所有可用的CPU核心，提高效率。 所以大并发下的最佳实践就是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。 go协程的GMP理论 # 首先协程和线程是多对多的关系，一般是多对一，只要不涉及多线程就不涉及抢占和线程上下文切换
G指goroutine M thread(machine)、P(Processor处理器)
在 Go 中，线程是运行 goroutine 的实体，调度器的功能是把可运行的 goroutine 分配到工作线程上。 全局队列（Global Queue）：存放等待运行的 G。 P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 一句话：协程创建先放入P的队列，放满了把一半放G的全局队列，M顺序取P来运行，如果M没有取到（P为空）移动全局队列到P中，或者去其他P上取，所以M有调度的作用</description></item><item><title/><link>https://leetcode.coding3min.com/interview/java/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/java/</guid><description>Java # 基本数据类型 # 整型：byte(8)、short(16)、int(32)、long(64) 浮点型：float(32)、double(64) 布尔型：boolean(8) 字符型：char(16) 只能向上转型 += 或者 ++ 运算符会执行隐式类型转换 异常处理 # 三种类型的异常 # **检查性异常：**最具代表的检查性异常是用户错误或问题引起的异常，这是程序员无法预见的。例如要打开一个不存在文件时，一个异常就发生了，这些异常在编译时不能被简单地忽略。 运行时异常： 运行时异常是可能被程序员避免的异常。与检查性异常相反，运行时异常可以在编译时被忽略。 错误： 错误不是异常，而是脱离程序员控制的问题。错误在代码中通常被忽略。例如，当栈溢出时，一个错误就发生了，它们在编译也检查不到的。 关键字 # try/catch：捕获异常，catch可以多重捕获（直到异常被捕获或者通过所有的 catch 块） throws/throw：方法使用 throws 关键字来声明（一个方法没有捕获到一个检查性异常），throw 关键字抛出一个异常 finally：在 try 代码块后面执行的代码块 自定义异常 # 所有异常都必须是 Throwable 的子类。 自定义检查性异常类，需要继承 Exception 类。 自定义运行时异常类，那么需要继承 RuntimeException 类。 hashMap # 底层数据结构，JDK 1.8 是数组 + 链表 + 红黑树，JDK 1.</description></item><item><title/><link>https://leetcode.coding3min.com/interview/k8s/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/k8s/</guid><description>k8s # 核心组件 # 主节点（Master）：kube-controller-manager，kube-apiserver，kube-scheduler 工作节点（Node）：kubelet和kube-proxy 只有apiserver使用etcd k8s的架构和组件是哪些，有哪些资源(api)类型？ # Kubernetes主要由以下几个核心组件组成：
etcd保存了整个集群的状态； apiserver提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制； controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等； scheduler负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上； kubelet负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理； Container runtime负责镜像管理以及Pod和容器的真正运行（CRI）； kube-proxy负责为Service提供cluster内部的服务发现和负载均衡； 除了核心组件，还有一些推荐的Add-ons：
kube-dns负责为整个集群提供DNS服务 Ingress Controller为服务提供外网入口 Heapster提供资源监控 Dashboard提供GUI Federation提供跨可用区的集群 Fluentd-elasticsearch提供集群日志采集、存储与查询 资源类型:
类别 名称 资源对象 Pod、ReplicaSet、ReplicationController、Deployment、StatefulSet、DaemonSet、Job、CronJob、HorizontalPodAutoscaling、Node、Namespace、Service、Ingress、Label、CustomResourceDefinition 存储对象 Volume、PersistentVolume、Secret、ConfigMap 策略对象 SecurityContext、ResourceQuota、LimitRange 身份对象 ServiceAccount、Role、ClusterRole 哪些组件和etcd打交道？ # etcd 保存了整个集群的状态，所以和操作资源相关的都要读写 etcd
注意：只有apiserver使用etcd，其他组件都是通过apiserver和etcd打交道</description></item><item><title/><link>https://leetcode.coding3min.com/interview/linux/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/linux/</guid><description>Linux # VIM 三个模式 # 一般指令模式（默认模式） 编辑模式 指令列模式 文件属性 # 用户分为三种 文件拥有者 群组 其它人 文件类型 d：目录 -：文件 l：链接文件 文件权限： 三位一组 对文件拥有者、所属群组以及其它人的文件权限 3 位分别为 r、w、x 权限，表示可读、可写、可执行 文件时间 modification time (mtime)：文件的内容更新就会更新； status time (ctime)：文件的状态（权限、属性）更新就会更新； access time (atime)：读取文件时就会更新。 修改权限 chmod 左到右每个位的权值为 4、2、1 默认权限 文件默认权限666 目录默认权限777 链接 # 实体链接：在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。 符号链接：文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式 ln创建链接：默认是实体链接，加 -s 为符号链接 获取文件内容 # cat、tac(从最后一行打印) more（一页一页打印）、less（增加向前翻页） head（前n行）、tail（后几行） 数据流重定向 # 一个箭头的表示以覆盖的方式重定向，而有两个箭头的表示以追加的方式重定向 输出重定向到 /dev/null（扔进垃圾箱） 排序指令（sort） # $ sort [-fbMnrtuk] [file or stdin] -f ：忽略大小写 -b ：忽略最前面的空格 -M ：以月份的名字来排序，例如 JAN，DEC -n ：使用数字 -r ：反向排序 -u ：相当于 unique，重复的内容只出现一次 -t ：分隔符，默认为 tab -k ：指定排序的区间 $ uniq [-ic](可以将重复的数据只取一个) -i ：忽略大小写 -c ：进行计数 正则表达式(grep) # $ grep [-acinv] [--color=auto] 搜寻字符串 filename -c ： 统计匹配到行的个数 -i ： 忽略大小写 -n ： 输出行号 -v ： 反向选择，也就是显示出没有 搜寻字符串 内容的那一行 --color=auto ：找到的关键字加颜色显示 查看进程 # ps -l 查看自己的进程 ps aux 查看系统所有进程 pstree 查看进程数 查看子进程的命令 # 这里的 722 是指进程 pid</description></item><item><title/><link>https://leetcode.coding3min.com/interview/mongodb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/mongodb/</guid><description>TODO-mongoDB # 请移步 面试高频问题-待解答</description></item><item><title/><link>https://leetcode.coding3min.com/interview/mysql/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/mysql/</guid><description>Mysql # 数据类型 # 整型：TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间 浮点数：FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型 字符串： CHAR（定长） 和 VARCHAR（变长的） 时间日期：date、datetime、timestamp（比DATETIME 空间效率更高） 存储引擎：myisam和innodb的区别是什么 # 答者：狸追
innodb 支持事务和外键，最小锁粒度是行级锁，myisam 不支持事务和外键，最小锁粒度是表级锁，间歇锁 innodb 的索引如果是聚簇索引，叶子节点上保存的是数据和索引，非聚簇索引，节点上保存的是id，而myisam保存的是数据的地址（相当于一个指针） myisam 的表可以没有索引，innodb一定要有索引 myisam 会保存总行数，innodb是全表扫描 总结：对于大量更新、插入、删除，innodb性能上更好，因为他具备的事务、行级锁、B+树等特点，更安全，因为回滚和崩溃恢复更适合大型应用 经过测试在单进程读的情况下myisam执行速度比innodb更快，但是多进程读的时候就失去优势了 mysql5.5版本之后默认innodb 展开说
MyISAM： 拥有较高的插入，查询速度 不支持事务 支持表级锁 不支持MVCC 不支持外键 支持全文索引 内部维护了一个计数器，selectcount更快 InnoDB ：插入缓冲（insert buffer)、二次写(double write)、自适应哈希索引(ahi)、预读(read ahead) 5.5版本后Mysql的默认数据库 支持ACID事务 支持行级锁定 支持MVCC 支持外键 不支持全文索引 不建议使用过长的字段作为主键：因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。 不建议用非单调的字段作为主键：因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 特殊的功能“自适应哈希索引”：当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引（B+Tree 索引具有哈希索引的一些优点） 主从复制 # 主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中 从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中 从：sql执行线程——执行relay log中的语句 索引类型 # 普通索引 唯一索引：索引列的值必须唯一，但允许有空值 主键索引：特殊的唯一索引，一个表只能有一个主键，不允许有空值 组合索引：在查询条件中使用了创建索引时的第一个字段，索引才会被使用。遵循最左前缀集合 全文索引：主要用来查找文本中的关键字（MATCH AGAINST） Mysql8新特性降序索引 聚集索引（主键索引）和非聚集索引 # 索引按照数据结构来说主要包含B+树和Hash索引。</description></item><item><title/><link>https://leetcode.coding3min.com/interview/network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/network/</guid><description>网络 # 计算机网络网络 # IP协议：一种分组交换传输协议； TCP协议：一种面向连接，可靠传输的协议； UDP协议：一种无连接，不可靠传输的协议。 操作系统抽象出Socket接口，每个应用程序需要各自对应到不同的Socket，数据包才能根据Socket正确地发到对应的应用程序 一个Socket由IP地址和端口号 小于1024的端口属于_特权端口_，需要管理员权限 使用Socket进行网络编程时，本质上就是两个进程之间的网络通信 服务器端的Socket是指定的IP地址和指定的端口号；客户端的Socket是它所在计算机的IP地址和一个由操作系统分配的随机端口号 三次握手 TCP客户端最后还要发送一次确认的原因：主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误 四次挥手 A 发送连接释放报文，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放报文，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 underlay就是底层承载网，overlay就是基于底层网络互联互通的基础加上隧道技术去构建一个虚拟的网络。overlay的核心其实就是打隧道（tunnel） http 中的 4层与7层分别代表什么，中间那三层是为了满足什么样的需求呢？ # 提问：小雨
答者：海翔
一个ISO7层模型，一个是web四层模型，不是一个东西 7层模型分物理层，数据链路层，网络层，传输层，会话层，表示层，应用层 4层模型是TCP/IP协议的定义，数据链路层对应7层模型的物理层+数据链路层，网络层对应7层模型的网络层，传输层对应7层模型的传输层，应用层对应7层模型的会话层+表示层+应用层 TCP # TCP 三次握手、四次挥手（重点） # 三次握手：1.</description></item><item><title/><link>https://leetcode.coding3min.com/interview/qian-duan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/qian-duan/</guid><description>TODO-前端 # 请移步 面试高频问题-待解答</description></item><item><title/><link>https://leetcode.coding3min.com/interview/queue/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/queue/</guid><description>消息队列 # 如何保证队列数据一致性，防止重复消费，幂等性 # 所有的消息中间件在实际的业务场景中都逃脱不了保证消息的一致性的问题
kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，可以理解成一个自增持的序号，一个个排下来
然后消费者consumer，每隔一段时间，就把自己消费过的消息提交一下，如果说出现宕机或者重启，则会继续从上次消费的序号接着往下排，继续消费
但是有的时候，消费者consumer消费的消息，由于各种原因，比如网络、宕机、停电。。。都没来得及写offset,这个时候少数消息会再次消费一次
这个时候，我们可以用一个唯一的id标识来区分，这不是消息中间件做的事，而是开发者要做的，比如你消费一个就往数据库插入一条记录，然后下次再去消费的时候，你去查一下，看看这个消息是否被消费了，消费了那就不要重复消费了。
（补充一下：确认一条数据在百万级别海量数据里是否存在？&amp;ndash;可以用布隆过滤器）
根据主键查一下，如果这数据都有了，就别插入了，update一下（虽然重复插入会因为唯一键约束而报错，我觉得我们还是应该避免报错） 如果是写redis，反正每次都是set，天然幂等性 如果不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，就别处理了，保证别重复处理相同的消息即可。 引用:
rabbitMq-kafka消息高可用，一致性 如何保证消息队列的高可用和幂等性以及数据丢失，顺序一致性 如何预防rabbitmq消息的丢失 # 情况1、生产者自己丢失了消息(网络故障/发送失败)
解决方案：
rabbitmq：一般这种都是采用回调接口的方案（confirm模式），就是说你扔一个消息过去了，对方给你一个回调接口，告诉你成功了或者失败了，失败了你可以选择继续扔消息， (重试机制等)，来保证消息一定送达
开启confirm模式（异步的）之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。
引用： 如何保证消息队列的高可用和幂等性以及数据丢失，顺序一致性
情况2、消息中间件弄丢了消息
解决方案：以rabbitmq来说，开启持久化就好了，当发生宕机的时候，queue会自动从磁盘恢复数据，除非极其罕见的是，rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小
情况3、消费者弄丢了消息
rabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，rabbitmq认为你都消费了，这数据就丢了。
关闭rabbitmq自动ack机制，可以通过一个api来调用，每次代码里确保处理完的时候，再程序里ack。这样的话，如果还没处理完，就没有ack，那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的
如何预防kafak消息丢失 # TODO
如何处理消息积压 # 出现场景：消费能力被阻塞（消费者挂掉或者处理速度慢），生产者还不停的往队列里扔消息
解决方法：
快速恢复consumer服务，慢慢消费，如果积压的数据量太大的话恢复较慢 临时写脚本快速的把这批消息给消费掉，或者增加消费者数量/消费速度，要避免负载把其他服务打挂 扩容：提高相同消息的队列数量，出现问题时写脚本分发到不同队列里，再给每个队列指定消费者，消费结束后再恢复 预防：
提前准备多个队列在投递时随机投递，存储同类型无顺序要求的消息 使用多个消费者 消息过期或者队列满了怎么办 # 消息队列TTL超时或者队列满了数据会丢失，这个时候可以自己再去找消息，然后临时写个代码，自己再手动的去把这些消息重新推送到队列里去。
另一种解决方案
可以在 rabbitmq 中声明死信队列，死信队列为处理过期或不能正确路由的消息提供了驻留场所，可以防止消息丢失，便于分析无法消费的原因 写程序处理死信队列里的数据，并接入告警分析 如果投递不成功，需要把数据暂存内存或者暂存redis之类的数据库中，等待恢复时重试</description></item><item><title/><link>https://leetcode.coding3min.com/interview/redis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/redis/</guid><description>Redis # 数据类型 # 键的类型只能为字符串 值支持五种数据类型： 字符串： set &amp;lt;key&amp;gt; &amp;lt;value&amp;gt; get &amp;lt;key&amp;gt; del &amp;lt;key&amp;gt; 列表 rpush &amp;lt;key&amp;gt; &amp;lt;item&amp;gt; lrange &amp;lt;key&amp;gt; i j（j可填-1） rindex &amp;lt;key&amp;gt; i lpop &amp;lt;key&amp;gt; 无序集合 sadd &amp;lt;key&amp;gt; &amp;lt;item&amp;gt; smembers &amp;lt;key&amp;gt; sismember &amp;lt;key&amp;gt; &amp;lt;item&amp;gt; srem &amp;lt;key&amp;gt; &amp;lt;item&amp;gt; 散列表 hset &amp;lt;key&amp;gt; &amp;lt;sub_key&amp;gt; &amp;lt;value&amp;gt; hgetall &amp;lt;key&amp;gt;（每条数据sub_key和value各占一行） hdel &amp;lt;key&amp;gt; &amp;lt;sub_key&amp;gt; 有序集合 zadd &amp;lt;key&amp;gt; &amp;lt;score&amp;gt; &amp;lt;item&amp;gt; zrange &amp;lt;key&amp;gt; i j withscores zrangebyscore &amp;lt;key&amp;gt; &amp;lt;score1&amp;gt; &amp;lt;score2&amp;gt; withscores zrem &amp;lt;key&amp;gt; &amp;lt;item&amp;gt; zset(sort list) 的数据结构是什么？ # zset 有序且唯一，在跳表以空间换时间 以冗余的链表换取效率</description></item><item><title/><link>https://leetcode.coding3min.com/interview/xiang-mu-wen-shi-mo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://leetcode.coding3min.com/interview/xiang-mu-wen-shi-mo/</guid><description>项目一般问什么 # 项目问题因人而异，但是这些问题是共性的，可以思考一下 # 你最有成就感，或者最有挑战的项目经过，解决什么样的问题 数据量很大还是并发量很高，并发量体现在哪里？QPS是多少？ 怎么提高可用性的？ 技术难点体现在哪里？ 你的项目有没有出现什么重大事故/故障，是怎么解决的，具体是什么原因 有没有什么印象深刻的Bug 分布式锁如何实现 # 分布式锁，一般为了达到分布式加锁需要通过投票的机制，依次向所有节点申请加锁，半数以上节点投票通过完成加锁，可以避免单点故障（Redis称为Redlock算法）
加锁的动作需要保证原子性，Redis通过Lua脚本来保证 谁加的锁谁来释放锁，所以需要标记锁来源 预防加锁程序挂掉导致的锁不释放，所以需要设置过期时间 加锁成功需要判断获取锁总耗时没有超过锁有效时间，这才判定为加锁成功 注意：假如程序处理速度比锁过期时间要长，是不合理的设计，超时时间的设置就很精细，一般都是远大于处理的时间，如果真的处理时间太长应该判定失败并告警
见 redis
如何实现一个分布式id生成器 # 首先要知道自增主键出现的问题
在高并发的情况下加入事务执行失败回滚，会跳过当前插入ID，使ID不连续 所有数据库中的自增字段或者自增序列都要记录日志，会产生磁盘IO，会成为性能瓶颈 假如数据库使用的是Range分片，自增ID可能会集中写入集群中的一个节点，出现数据访问热地世，性能退化成单机写入 解决方案
随机主键UUID方案（32 个的 16 进制数字，16^32 = 2^128 就是128位），虽然可以保证每次随机都不一样，但缺点是键值长度过长，存储和计算的代价增加，uuid只能保证不重复，但数据页可能会分裂，影响查询性能 号段模式，每个业务批量获取数据库中的号段，比如一次获取1000个，然后内存生成1000个自增ID，使用完再获取1000个；只需要插入一条记录，步长设置为1000，注意使用乐观锁（维护版本号），记录字段有业务类型、当前最大可用id、号段步长，version号；缺点服务重启时重新申请号段，不够随机有被猜到的风险 在TiDB 里提供了一种AutoRandom的算法，生成64位整型随机ID，1bit符号位、5bit事务开始时间，58bit自增序列号，还是有可能出现尾部热点 雪花算法Snowflake，时间戳精确到毫秒，10位长度机器码最大规模1024个节点(2^10), 12位序列代表1毫秒能产生的id数量最多4096个。所以 TPS 可以达到 419 万左右（2^22*1000）, 每秒那么多大多系统都够了 注意雪花算法，对时间的要求比较高，如果时间不同步，时钟回拨时 ID 有可能出现重复
引用： 分布式数据库30讲
如何优化雪花算法的问题 # 雪花算法的问题主要在于时间回拨出现id重复、机器id有上限
时钟回拨就是本机时间略快，完成时间服务器的校准（NTP或者闰秒回拨）以后，会出现时间倒退，导致生成ID重复
时钟回拨解决办法：
继续在当前ID序列号最大基础上增加，方案来自 snowflake算法的时钟回拨问题如何解决 如果时间偏差比较小，&amp;lt;=5ms 可以等待2倍时间，牺牲很短时间的可用性，方案来自 SnowFlakeID原理和改进优化 时间回拨跨度太大时告警，并摘除本身节点，只会影响一个节点 也可以考虑直接关闭时间同步 机器id有上限的解决办法（雪花算法优化）</description></item></channel></rss>